

	@inproceedings{92,
	author={Ren, Xiaodong and Du, Sanping and Zheng, Yi},
	title={Parallel RCNN: A deep learning method for people detection using RGB-D images}, 
	booktitle={2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
	year={2017},
	pages={1-6}}

	@inproceedings{91,
	author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
	title={DPDnet: A robust people detector using deep learning with an overhead depth camera},
	booktitle={Proceedings of the European Conference on Computer Vision},
	year={2016},
	pages={525-542},
	organization={Springer}}

	@inproceedings{90,
	author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
	title={Xnor-net: Imagenet classification using binary convolutional neural networks},
	booktitle={Proceedings of the European Conference on Computer Vision},
	year={2016},
	pages={525--542},
	organization={Springer}}

	@article{89,
	author={Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
	title={Binarized neural networks: Training deep neural networks with weights and activations constrained to +1 or -1},
	journal={arXiv preprint arXiv:1602.02830},
	year={2016}}

	@inproceedings{88,
	author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
	title={Deep learning with limited numerical precision},
	booktitle={Proceedings of the International Conference on Machine Learning},
	year={2015},
	pages={1737--1746},
	organization={PMLR}}

	@article{87,
	author={Gong, Yunchao and Liu, Liu and Yang, Ming and Bourdev, Lubomir},
	title={Compressing deep convolutional networks using vector quantization},
	journal={arXiv preprint arXiv:1412.6115},
	year={2014}}

	@inproceedings{86,
	author={Chen, Wenlin and Wilson, James and Tyree, Stephen and Weinberger, Kilian and Chen, Yixin},
	title={Compressing neural networks with the hashing trick},
	booktitle={Pro-ceedings of the International Conference on Machine Learning},
	year={2015},
	pages={2285--2294},
	organization={PMLR}}

	@inproceedings{85,
	author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
	title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2704-2713},
	year={2018},
	organization={IEEE}}

	@article{84,
	author={Vincent {Vanhoucke} and Andrew {Senior} and Mark Z. {Mao}},
	title={Improving the speed of neural networks on cpus},
	journal={Advances in Neural Information Processing Systems Workshop},
	year={2011}}

	@inproceedings{83,
	title={Fixed point quantization of deep convolutional networks},
	author={Lin, Darryl and Talathi, Sachin and Annapureddy, Sreekanth},
	booktitle={Proceedings of the International Conference on Machine Learning},
	year={2016},
	pages={2849-2858}}

	@inproceedings{82,
	author={Hou, Qibin and Zhou, Daquan and Feng, Jiashi},
	title={Coordinate attention for efficient mobile network design},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={13713-13722},
	year={2021},
	organization={IEEE}}
  
	@inproceedings{81,
	author={Han, Kai and Wang, Yunhe and Tian, Qi and Guo, Jianyuan and Xu, Chunjing and Xu, Chang},
	title={Ghostnet: More features from cheap operations},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	year={2020},
	pages={1580-1589},
	organization={IEEE}}

	@inproceedings{80,
	author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
	title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
	booktitle={Proceedings of the European conference on computer vision (ECCV)},
	year={2018},
	pages={116-131}}

	@inproceedings{79,
	author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
	title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	year={2018},
	pages={6848-6856},
	organization={IEEE}}

	@inproceedings{78,
	author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
	title={Searching for mobilenetv3},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	year={2019},
	pages={1314-1324},
	organization={IEEE}}

	@inproceedings{77,
	author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	title={Mobilenetv2: Inverted residuals and linear bottlenecks},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	year={2018},
	pages={4510-4520},
	organization={IEEE}}

	@article{76,
	author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
	journal={arXiv preprint arXiv:1704.04861},
	year={2017}}

	@article{75,
	author={Han, Song and Mao, Huizi and Dally, William J},
	title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
	journal={arXiv preprint arXiv:1510.00149},
	year={2015}}

	@article{74,
	author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
	title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
	journal={arXiv preprint arXiv:1602.07360},
	year={2016}}

	@inproceedings{73,
	Author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	Title = {Deep residual learning for image recognition},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	Year = {2016},
	Pages = {770--778},
	organization={IEEE}}

	@article{72,
	author={Henriques, Jo{\~a}o F and Caseiro, Rui and Martins, Pedro and Batista, Jorge},
	title={High-speed tracking with kernelized correlation filters},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2014},
	volume={37},
	number={3},
	pages={583-596},
	publisher={IEEE}}

	@inproceedings{71,
	author={Jia, Xu and Lu, Huchuan and Yang, Ming-Hsuan},
	title={Visual tracking via adaptive structural local sparse appearance model},
	booktitle={2012 IEEE Conference on computer vision and pattern recognition},
	year={2012},
	pages={1822-1829},
	organization={IEEE}}


	@inproceedings{70,
	author={Zhong, Wei and Lu, Huchuan and Yang, Ming-Hsuan},
	title={Robust object tracking via sparsity-based collaborative model},
	booktitle={2012 IEEE Conference on Computer vision and pattern recognition},
	year={2012},
	pages={1838-1845},
	organization={IEEE}}

	@article{69,
	author={Hare, Sam and Golodetz, Stuart and Saffari, Amir and Vineet, Vibhav and Cheng, Ming-Ming and Hicks, Stephen L and Torr, Philip HS},
	title={Struck: Structured output tracking with kernels},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2015},
	volume={38},
	number={10},
	pages={2096--2109},
	publisher={IEEE}}

	@article{68,
	author={Zhang, Kaihua and Zhang, Lei and Yang, Ming-Hsuan},
	title={Fast compressive tracking},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2014},
	volume={36},
	number={10},
	pages={2002-2015},
	publisher={IEEE}}

	@inproceedings{67,
	title={Robust visual tracking using $\ell_1$ minimization},
	author={Mei, Xue and Ling, Haibin},
	booktitle={2009 IEEE 12th international conference on computer vision},
	pages={1436-1443},
	year={2009},
	organization={IEEE}}

	@article{66,
	author={Babenko, Boris and Yang, Ming-Hsuan and Belongie, Serge},
	title={Robust object tracking with online multiple instance learning},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2010},
	volume={33},
	number={8},
	pages={1619-1632},
	publisher={IEEE}}

	@inproceedings{65,
	author={Babenko, Boris and Yang, Ming-Hsuan and Belongie, Serge},
	title={Visual tracking with online multiple instance learning},
	booktitle={2009 IEEE Conference on computer vision and Pattern Recognition},
	year={2009},
	pages={983-990}}

	@article{64,
	author={Ross, David A and Lim, Jongwoo and Lin, Ruei-Sung and Yang, Ming-Hsuan},
	title={Incremental learning for robust visual tracking},
	journal={International journal of computer vision},
	year={2008},
	volume={77},
	number={1},
	pages={125-141},
	publisher={Springer}}

	@article{63,
	author={Hager, Gregory D and Belhumeur, Peter N},
	title={Efficient region tracking with parametric models of geometry and illumination},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={1998},
	volume={20},
	number={10},
	pages={1025-1039},
	publisher={IEEE}}

	@article{62,
	author={Grabner, Helmut and Grabner, Michael and Bischof, Horst},
	title={Real-Time Tracking via On-line Boosting On line Boosting},
	publisher={Institute for Computer Graphics and Vision Graz University of Technology}}

	@article{61,
	author={Avidan, Shai},
	title={Ensemble tracking},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2007},
	volume={29},
	number={2},
	pages={261-271},
	publisher={IEEE}}

	@article{60,
	author={Avidan, Shai},
	title={Support vector tracking},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2004},
	volume={26},
	number={8},
	pages={1064-1072},
	publisher={IEEE}}

	@inproceedings{59,
	author={Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},
	title={Simple online and realtime tracking},
	booktitle={2016 IEEE international conference on image processing (ICIP)},
	year={2016},
	pages={3464-3468}}

	@inproceedings{58,
	author={Nouar, O-D and Ali, Ganoun and Rapha{\"e}l, Canals},
	title={Improved object tracking with camshift algorithm},
	booktitle={2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings},
	year={2006},
	volume={2},
	pages={2-2}}

	@article{57,
	author={Comaniciu, Dorin and Ramesh, Visvanathan and Meer, Peter},
	title={Kernel-based object tracking},
	journal={IEEE Transactions on pattern analysis and machine intelligence},
	year={2003},
	volume={25},
	number={5},
	pages={564--577},
	publisher={IEEE}}

	@inproceedings{56,
	author={Comaniciu, Dorin and Ramesh, Visvanathan and Meer, Peter},
	title={Real-time tracking of non-rigid objects using mean shift},
	booktitle={Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662)},
	volume={2},
	year={2000},
	pages={142-149}}

	@article{55,
	author={Cheng, Yizong},
	title={Mean shift, mode seeking, and clustering},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={1995},
	volume={17},
	number={8},
	pages={790-799},
	publisher={IEEE}}

	@article{54,
	author={Fukunaga, Keinosuke and Hostetler, Larry},
	title={The estimation of the gradient of a density function, with applications in pattern recognition},
	journal={IEEE Transactions on information theory},
	year={1975},
	volume={21},
	number={1},
	pages={32-40},
	publisher={IEEE}}

	@inproceedings{53,
	author={Gordon, Neil J and Salmond, David J and Smith, Adrian FM},
	title={Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
	booktitle={IEE proceedings F (radar and signal processing)},
	year={1993},
	volume={140},
	pages={107-113}}

	@article{52,
	author={Maskell, Simon and Gordon, Neil},
	title={A tutorial on particle filters for on-line nonlinear/non-Gaussian Bayesian tracking},
	journal={IEE Target Tracking: Algorithms and Applications (Ref. No. 2001/174)},
	year={2002},
	pages={1-2},
	publisher={IET}}

	@article{51,
	author={Metropolis, Nicholas and Ulam, Stanislaw},
	title={The monte carlo method},
	journal={Journal of the American statistical association},
	year={1949},
	volume={44},
	number={247},
	pages={335-341},
	publisher={Taylor \& Francis}}

	@article{50,
	author={Doucet, Arnaud and Johansen, Adam M and others},
	title={A tutorial on particle filtering and smoothing: Fifteen years later},
	journal={Handbook of nonlinear filtering},
	year={2009},
	volume={12},
	number={656-704},
	pages={3}}

	@article{49,
	author={Arasaratnam, Ienkaran and Haykin, Simon},
	title={Cubature kalman filters},
	journal={IEEE Transactions on automatic control},
	year={2009},
	volume={54},
	number={6},
	pages={1254-1269},
	publisher={IEEE}}

	@inproceedings{48,
	author={Julier, Simon J and Uhlmann, Jeffrey K},
	title={New extension of the Kalman filter to nonlinear systems},
	booktitle={Signal processing, sensor fusion, and target recognition VI},
	year={1997},
	volume={3068},
	pages={182-193}}

	@article{47,
	author={Terejanu, Gabriel A and others},
	title={Extended kalman filter tutorial},
	journal={University at Buffalo},
	year={2008}}
  
	@book{46,
	author={Jazwinski, Andrew H},
	title={Stochastic processes and filtering theory},
	year={2007},
	publisher={Courier Corporation}}

	@InProceedings{45,
	author={Welch, G. and G. Bishop},
	title={An Introduction to the Kalman Filter},
	booktitle={University of North Carolina at Chapel Hill},
	year={1997}}

	@article{44,
    author = {Kalman, R. E.},
    title = {A New Approach to Linear Filtering and Prediction Problems},
    journal = {Journal of Basic Engineering},
	year = {1960},
    volume = {82},
    number = {1},
    pages = {35-45}}

	@InProceedings{43,
	author = {Lin, Tsung-Yi and Dollar, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
	title = {Feature Pyramid Networks for Object Detection},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2017},
	pages={2117-2125}} 

	@InProceedings{42,
	author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitruand Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	title={SSD: Single Shot MultiBox Detector},
	booktitle={Computer Vision -- ECCV 2016},
	year={2016},
	pages={21-37}}

	@INPROCEEDINGS{41,
	author={Ahmad, Misbah and Ahmed, Imran and Ullah, Kaleem and Ahmad, Maaz},
	title={A Deep Neural Network Approach for Top View People Detection and Counting}, 
	booktitle={2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, 
	year={2019},
	pages={1082-1088}}

	@misc{40,
	author = {Redmon, Joseph and Farhadi, Ali},
	title = {YOLOv3: An Incremental Improvement},
	publisher = {arXiv},
	year = {2018}}

	@InProceedings{39,
	author = {Redmon, Joseph and Farhadi, Ali},
	title = {YOLO9000: Better, Faster, Stronger},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2017},
	pages = {7263-7271}} 

	@InProceedings{38,
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	title = {Going Deeper With Convolutions},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2015},
	pages = {1-9}} 

	@InProceedings{37,
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2016},
	pages = {779-788}} 

	@InProceedings{36,
	author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
	title = {Mask R-CNN},
	booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
	year = {2017},
	pages = {2961-2969}} 

	@article{35,
	author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	journal={Advances in neural information processing systems},
	title={Faster r-cnn: Towards real-time object detection with region proposal networks},
	year={2015},
	volume={28},
	pages={1137-1149}}

	@inproceedings{34,
	author = {Girshick, Ross},
	title = {Fast R-CNN},
	booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
	year = {2015},
	pages = {1440-1448}} 

	@article{33,
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition}, 
	year={2015},
	volume={37},
	number={9},
	pages={1904-1916}}

	@inproceedings{32,
	author={Christian Ertler and Horst Possegger and Michael Opitz and Horst Bischof},
	title={Pedestrian Detection in RGB-D Images from an Elevated Viewpoint},
	Booktitle = {22nd Computer Vision Winter Workshop},
	year={2017}}

	@inproceedings{31,
	Author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	Title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
	Booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
	Year = {2014},
	Pages = {580-587}}

	@misc{30,
	author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann},
	title = {OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks},
	publisher = {arXiv},
	year = {2013}}

	@inproceedings{29,
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	Title = {Imagenet classification with deep convolutional neural networks},
	Booktitle = {Advances in Neural Information Processing Systems},
	Year = {2012},
	Pages = {1097--1105}}

	@article{28,
	author = {Carlos A. Luna and Cristina Losada-Gutierrez and David Fuentes-Jimenez and Alvaro Fernandez-Rincon and Manuel Mazo and Javier Macias-Guarasa},
	journal = {Expert Systems with Applications},
	title = {Robust people detection using depth information from an overhead Time-of-Flight camera},
	volume = {71},
	pages = {240-256},
	year = {2017}}

	@inproceedings{27,
	Author = {Yu, Shiqi and Wu, Shengyin and Wang, Liang},
	Title = {SLTP: A Fast Descriptor for People Detection in Depth Images},
	Booktitle = {2012 IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance},
	Year = {2012},
	Pages = {43-47}}

	@article{26,
	author={Comaniciu, D. and Meer, P.},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Mean shift: a robust approach toward feature space analysis}, 
	year={2002},
	volume={24},
	number={5},
	pages={603-619}}
  
	@inproceedings{25,
	Author = {Rauter, Michael},
	Title = {Reliable Human Detection and Tracking in Top-View Depth Images},
	Booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops},
	Year = {2013},
	Pages = {529-534}}

	@inproceedings{24,
	Author = {Yan, Junjie and Lei, Zhen and Wen, Longyin and Li, Stan Z.},
	Title = {The Fastest Deformable Part Model for Object Detection},
	Booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
	Year = {2014},
	Pages = {2497-2504}}

	@inproceedings{23,
	Author = {Felzenszwalb, Pedro and McAllester, David and Ramanan, Deva},
	Title = {A discriminatively trained, multiscale, deformable part model},
	Booktitle = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
	Year = {2008},
	Pages = {1-8}}

	@inproceedings{22,
	Author = {Dollár, Piotr and Tu, Zhuowen and Perona, Pietro and Belongie, Serge},
	Title = {Integral Channel Features},
	Booktitle = {Proceedings of the British Machine Vision Conference},
	Year = {2009},
	Pages = {91.1-91.11}}

	@inproceedings{21,
	Author = {Ahmed, Imran and Carter, John N.},
	Title = {A robust person detector for overhead views},
	Booktitle = {Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},
	Year = {2012},
	Pages = {1483-1486}}

	@article{20,
	author={Pang, Yanwei and Yan, He and Yuan, Yuan and Wang, Kongqiao},
  	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
  	title={Robust CoHOG Feature Extraction in Human-Centered Image/Video Management System}, 
  	year={2012},
  	volume={42},
	number={2},
  	pages={458-468}}

	@inproceedings{19,
	Author = {Lowe, D.G.},
	Title = {Object recognition from local scale-invariant features},
	Booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
	Year = {1999},
	volume = {2},
	Pages = {1150-1157}}

	@inproceedings{18,
	Author = {Dalal, N. and Triggs, B.},
	Title = {Histograms of oriented gradients for human detection},
	Booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
	Year = {2005},
	volume = {1},
	Pages = {886-893}}

	@article{17,
	author = {Hanzi Wang and David Suter},
	journal = {Pattern Recognition},
	title = {A consensus-based method for tracking: Modelling background scenario and foreground appearance},
	year = {2007},
	volume = {40},
	number = {3},
	pages = {1091-1105}}

	@inproceedings{16,
	Author = {Hofmann, Martin and Tiefenbacher, Philipp and Rigoll, Gerhard},
	Title = {Background segmentation with feedback: The Pixel-Based Adaptive Segmenter},
	Booktitle = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	Year = {2012},
	Pages = {38-43}}

	@article{15,
	author={Barnich, Olivier and Van Droogenbroeck, Marc},
	journal={IEEE Transactions on Image Processing}, 
	title={ViBe: A Universal Background Subtraction Algorithm for Video Sequences}, 
	year={2011},
	volume={20},
	number={6},
	pages={1709-1724}}

	@inproceedings{14,
	Author = {Stec, Michal and Herrmann, Viktor and Stabernack, Benno},
	Title = {Using Time-of-Flight sensors for people counting applications},
	Booktitle = {2019 Conference on Design and Architectures for Signal and Image Processing (DASIP)},
	Year = {2012},
	volume = {75},
	Pages = {59-64}}

	@inproceedings{13,
	Author = {Zhang, Xucong and Yan, Junjie and Feng, Shikun and Lei, Zhen and Yi, Dong and Li, Stan Z.},
	Title = {Water Filling: Unsupervised People Counting via Vertical Kinect Sensor},
	Booktitle = {2012 IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance},
	Year = {2012},
	Pages = {215-220}}

	@inproceedings{12,
	Author = {Rabah Iguernaissi, Djamal Merad and Pierre Drap},
	Title = {People Counting based on Kinect Depth Data},
	Booktitle = {ICPRAM -7th International Conference on Pattern Recognition Applications and Methods},
	Year = {2018},
	volume = {75},
	Pages = {364-370}}

	@inproceedings{11,
	Author = {S. Mukherjee, B. Saha, I. Jamal, R. Leclerc and N. Ray},
	Title = {Anovel framework for automatic passenger counting},
	Booktitle = {2011 18th IEEE International Conference on Image Processing},
	Year = {2011},
	Pages = {2969-2972}}
	
	@inproceedings{10,
	Author = {Bevilacqua, Alessandro and Stefano, Luigi Di and Azzari, Pietro},
	Title = {People tracking using a Time-of-Flight depth sensor},
	Booktitle = {2006 IEEE International Conference on Video and Signal Based Surveillance},
	Year = {2006},
	Pages = {89-89}}
	
	@inproceedings{9,
	Author = {Chenqiang Gao and Jun Liu and Qi Feng and Jing Lv},
	Title = {People-flow counting in complex environments by combining depth and color information},
	Booktitle = {Multimedia Tools and Applications},
	Year = {2016},
	volume = {75},
	Pages = {9315-9331}}
	
	@inproceedings{8,
	Author = {Ozturk, Ovgu and Toshihiko Yamasaki and Kiyoharu Aizawa},
	Title = {Tracking of humans and estimation of body/head orientation from top-view single camera for visual focus of attention analysis},
	Booktitle = {2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops},
	Year = {2009},
	Pages = {1020-1027}}

	@inproceedings{7,
	Author = {García, Jorge and Gardel, Alfredo and Bravo, Ignacio and Lázaro, José Luis and Martínez, Miguel and Rodríguez, David},
	Title = {Directional People Counter Based on Head Tracking},
	Booktitle = {IEEE Transactions on Industrial Electronics},
	Year = {2013},
	volume = {60},
	Pages = {3991-4000}}

	@inproceedings{6,
	Author = {Perng, Jau-Woei and Wang, Ting-Yen and Hsu, Ya-Wen and Wu, Bing-Fei},
	Title = {The design and implementation of a vision-based people counting system in buses},
	Booktitle = {2016 International Conference on System Science and Engineering (ICSSE)},
	Year = {2016},
	Pages = {1-3}}

	@inproceedings{5,
	Author = {Tang-Wei Hsu and Yu-Huan Yang and Tso-Hsin Yeh and An-Sheng Liu and Fu, Li-Chen and Yi-Chong Zeng},
	Title = {Privacy free indoor action detection system using top-view depth camera based on key-poses},
	Booktitle = {2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
	Year = {2016},
	Pages = {004058-004063}}

	@inproceedings{4,
	Author = {Vera, P. and S. Monjaraz, and J. Salas},
	Title = {Counting pedestrians with a zenithal arrangement of depth cameras},
	Booktitle = {Machine Vision and Applications},
	Pages = {303-315},
	Year = {2016}}

	@article{3,
	author = {Deva, Ramanan and Forsyth, {David A.} and Andrew, Zisserman},
	title = {Tracking people by learning their appearance},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year = {2007},
	volume = {29},
	pages = {65-81}}

	@article{2,
	author = {Misbah, Ahmad and Imran, Ahmed and Kaleem, Ullah and Iqbal, khan and Ayesha, Khattak and Awais, Adnan},
	title = {Person Detection from Overhead View: A Survey},
	journal = {International Journal of Advanced Computer Science and Applications},
	year = {2019},
	volume = {10}} 

	@book{1,
	Author = {Heidelberg},
	Title = {TOF Range-Imaging Cameras},
	publisher = {Springer},
	Year = {2013}}




\chapter{绪论}
\section{研究背景及意义}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap1/depth_image.png}
	\caption{\ \ 深度图像特征}
	\label{fig1-1}
\end{figure}
\section{国内外研究现状}
\subsection{多目标检测}
\subsection{多目标追踪}
\subsection{模型轻量化与硬件加速}
\section{本文研究内容}
\section{本文结构安排}

\chapter{基于深度图像特征的卷积神经网络多目标检测算法}
\section{问题概述}
\section{数据集采集与简介}
\section{基于深度图像的多目标检测卷积神经网络架构}
\vspace{3mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/CBS.png}
	\caption{\ \ CBS 模块}
	\label{fig2-1}
\end{figure}
\vspace{3mm}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/C3.png}
	\caption{\ \ C3 模块}
	\label{fig2-2}
\end{figure}
\vspace{3mm}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/Bottleneck.png}
	\caption{\ \ BottleNeck 模块}
	\label{fig2-3}
\end{figure}
\vspace{3mm}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/SPPF.png}
	\caption{\ \ SPPF 模块}
	\label{fig2-4}
\end{figure}
\vspace{3mm}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/YOLOv5.png}
	\caption{\ \ YOLOv5 6.0 网络框架}
	\label{fig2-5}
\end{figure}
\vspace{3mm}
\section{实验}
\subsection{实验环境}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/surveillance.jpg}
	\caption{\ \ 监测示意图}
	\label{fig2-6}
\end{figure}
\vspace{3mm}
\subsection{实验结果}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/GOTPD.jpg}
	\caption{\ \ GOTPD 数据集检测结果}
	\label{fig2-7}
\end{figure}
\vspace{3mm}
\begin{figure}[htbp]
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/GOTPDF1.png}
		\caption{\ \ F1-curve}
		\label{fig2-8}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/GOTPDPR.png}
		\caption{\ \ PR-curve}
		\label{fig2-9}%文中引用该图片代号
	\end{minipage}
\end{figure}
\vspace{6mm}
\begin{figure}[htbp]
	\centering
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/TOFC1.png}
		\caption{\ \ $TOFC_1$}
		\label{fig2-10}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/TOFC2.png}
		\caption{\ \ $TOFC_2$}
		\label{fig2-11}%文中引用该图片代号
	\end{minipage}
\end{figure}
\begin{figure}[htbp]
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/TOFCF1.png}
		\caption{\ \ F1-curve}
		\label{fig2-12}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/TOFCPR.png}
		\caption{\ \ PR-curve}
		\label{fig2-13}%文中引用该图片代号
	\end{minipage}
\end{figure}
\vspace{3mm}
\begin{figure}[htbp]
	\centering
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/Axon1.png}
		\caption{\ \ $Axon_1$}
		\label{fig2-14}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/Axon2.png}
		\caption{\ \ $Axon_2$}
		\label{fig2-15}%文中引用该图片代号
	\end{minipage}
\end{figure}
\begin{figure}[htbp]
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/AxonF1.png}
		\caption{\ \ F1-curve}
		\label{fig2-16}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/AxonPR.png}
		\caption{\ \ PR-curve}
		\label{fig2-17}%文中引用该图片代号
	\end{minipage}
\end{figure}
\begin{figure}[htbp]
	\centering
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/v21.png}
		\caption{\ \ $v2_1$}
		\label{fig2-18}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/v22.png}
		\caption{\ \ $v2_2$}
		\label{fig2-19}%文中引用该图片代号
	\end{minipage}
\end{figure}
\begin{figure}[htbp]
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/v2F1.png}
		\caption{\ \ F1-curve}
		\label{fig2-20}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/v2PR.png}
		\caption{\ \ PR-curve}
		\label{fig2-21}%文中引用该图片代号
	\end{minipage}
\end{figure}
\begin{figure}[htbp]
	\centering
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/v41.png}
		\caption{\ \ $v4_1$}
		\label{fig2-22}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap2/v42.png}
		\caption{\ \ $v4_2$}
		\label{fig2-23}%文中引用该图片代号
	\end{minipage}
\end{figure}
\begin{figure}[htbp]
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/v4F1.jpg}
		\caption{\ \ F1-curve}
		\label{fig2-24}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{chap2/v4PR.jpg}
		\caption{\ \ PR-curve}
		\label{fig2-25}%文中引用该图片代号
	\end{minipage}
\end{figure}

\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/GOTPDETEC.png}
	\caption{\ \ GOTPD 推理过程可视化结果}
	\label{fig2-26}
\end{figure}
\vspace{3mm}
\subsection{与现有方法的比较}
\begin{table} [htpb]
	\begin{center}
		%\setlength{\belowcaptionskip}{3mm}
		\caption{\ \ 多目标检测方法准确度对比}
		\label{table2-1}
		\footnotesize
		%\setlength{\tabcolsep}{1.8pt}
		\begin{tabular}{llrrrrrrr}
			\hline
			\multirow{1}*{Methods} & \multirow{1}*{Input Data} & \multirow{1}*{Dataset} & \multirow{1}*{View} & \multirow{1}*{TPR} & \multirow{1}*{FPR} & \multirow{1}*{mAP@0.5}\\
			\hline \hline
			%You Only Look Once
			Fast YOLO \cite{37} & RGB & VOC2007+2012 & sideview & - & - & 0.527\\
			YOLO \cite{37} & RGB & VOC2007+2012 & sideview & - & - & 0.664\\
			%YOLOv3 : An Incremental Improvement
			SSD513 \cite{40} & RGB & COCO & sideview & - & - & 0.504\\
			YOLOv3 \cite{40} & RGB & COCO & sideview & - & - & 0.579\\
			%SSD Single Shot MultiBox Detector 
			Faster R-CNN \cite{42} & RGB & VOC2007+2012 & sideview & - & - & 0.704\\
			SSD300 \cite{42} & RGB & VOC2007+2012 & sideview & - & - & 0.724\\
			SSD512 \cite{42} & RGB & VOC2007+2012 & sideview & - & - & 0.749\\
			Faster R-CNN \cite{42} & RGB & VOC2007+2012+COCO & sideview & - & - & 0.759\\
			SSD300 \cite{42} & RGB & VOC2007+2012+COCO & sideview & - & - & 0.775\\
			SSD512 \cite{42} & RGB & VOC2007+2012+COCO & sideview & - & - & 0.800\\
			%A Deep Neural Network Approach for Top View People Detection and Counting
			SSD \cite{41} & RGB & - & topview & 94.42 & 0.17 & - \\
			Parallel RCNN \cite{92} & RGB-D & - & sideview & - & - & 0.915 \\
			%DPDnet
			Waterfilling \cite{13} & Depth & GOTPD & topview & 99.70 & 9.24 & 0.988\\
			DPDnet \cite{91} & Depth & GOTPD & topview & 99.87 & 0.25 & -\\ 
			%Ours
			\textbf{YOLOv5 6.0} & Depth & GOTPD+ToFC+Azure Kinect & topview & \textbf{99.90} & \textbf{0.10} & \textbf{0.994}\\

			\hline
		\end{tabular}
	\end{center}
\end{table}
\section{本章小结}

\chapter{基于深度图像特征的多目标追踪算法}
\section{问题概述}
\section{DeepSort算法研究}
\section{基于深度特征的多目标追踪算法}
\subsection{基于深度特征的多目标追踪算法设计}

\subsection{追踪算法优化结果对比}
\begin{table} [htpb]
	\begin{center}
		%\setlength{\belowcaptionskip}{3mm}
		\caption{\ \ 实时监测系统效果对比示意}
		\label{table3-1}
		\footnotesize
		%\setlength{\tabcolsep}{1.8pt}
		\begin{tabular}{llrrrr}
			\hline
			\multirow{1}*{应用平台} & \multirow{1}*{是否应用 GPU } & \multirow{1}*{网络层数} & \multirow{1}*{是否应用基于深度特征的追踪算法} & \multirow{1}*{实时监测帧率（FPS）}\\
			\hline \hline
			% $\checkmark$
			PC &  \ \ \ \ \ \ \ \ \ \ \ - & 192 & -\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 35.03\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			PC &  \ \ \ \ \ \ \ \ \ \ \ - & 192 & $\checkmark$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 54.39\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			PC &  \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 192 & -\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 55.36\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			PC &  \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 192 & $\checkmark$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 64.57\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			\hline
		\end{tabular}
	\end{center}
\end{table}
\section{本章小结}

\chapter{联合多应用场景下的人体检测追踪的网络轻量化和加速以及监测系统实现}
\section{问题概述}
\section{多目标监测系统简介}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap2/surveillance.jpg}
	\caption{\ \ 监测示意图}
	\label{fig4-1}
\end{figure}
\vspace{3mm}
\section{应用的轻量化模型架构}
\subsection{整体架构}
\subsection{模型轻量化}
\subsubsection{网络模型计算量指标FLOPs介绍}
\subsubsection{ShuffleNet}
\vspace{6mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/Shuffle.png}
	\caption{\ \ 逐点组卷积}
	\label{fig4-2}
\end{figure}
\vspace{3mm}
\vspace{3mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/Shuffle0.png}
	\caption{\ \ 通道混排操作过程}
	\label{fig4-3}
\end{figure}
\vspace{3mm}
\vspace{3mm}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/Shuffle1.png}
	\caption{\ \ ShuffleNet v2 网络结构}
	\label{fig4-4}
\end{figure}
\vspace{3mm}
\subsubsection{MobileNet}
\begin{figure}[htbp]
	\centering
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap4/Mobile2.jpg}
		\caption{\ \ 深度卷积}
		\label{fig4-5}%文中引用该图片代号
	\end{minipage}
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=1.0\linewidth]{chap4/Mobile3.jpg}
		\caption{\ \ 逐点卷积}
		\label{fig4-6}%文中引用该图片代号
	\end{minipage}
\end{figure}
\vspace{3mm}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\linewidth]{chap4/Mobile4.png}
	\caption{\ \ $1\times 1$卷积简化流程示意图}
	\label{fig4-7}
\end{figure}
\vspace{3mm}
\subsubsection{GhostNet}
\vspace{3mm}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/Ghost1.png}
	\caption{\ \ Ghost 对}
	\label{fig4-8}
\end{figure}
\vspace{3mm}
\vspace{3mm}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/Ghost2.png}
	\caption{\ \ Ghost Module}
	\label{fig4-9}
\end{figure}
\vspace{3mm}
\vspace{3mm}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/Ghost3.png}
	\caption{\ \ Ghost BottleNeck}
	\label{fig4-10}
\end{figure}
\subsubsection{CA}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.67\linewidth]{chap4/CA.png}
	\caption{\ \ CA 注意力机制效果示意图}
	\label{fig4-11}
\end{figure}
\subsection{硬件量化加速}
\section{实验}
\subsection{实验设置}
\subsection{网络轻量化效果对比实验}
\begin{table} [htpb]
	\begin{center}
		%\setlength{\belowcaptionskip}{3mm}
		\caption{\ \ 多目标检测模型轻量化结果对比示意}
		\label{table4-1}
		\footnotesize
		%\setlength{\tabcolsep}{1.8pt}
		\begin{tabular}{llrrrrrrr}
			\hline
			\multirow{1}*{模型种类} & \multirow{1}*{是否应用 GPU } & \multirow{1}*{网络层数} & \multirow{1}*{参数量} & \multirow{1}*{浮点运算数（FLOPs）} & \multirow{1}*{帧率（FPS）}\\
			\hline \hline
			% $\checkmark$
			ShuffleNet & \ \ \ \ \ \ \ \ \ \ \ - & 181 & 4518 & 0.1G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 19.53\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			ShuffleNet & \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 181 & 4518 & 0.1G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 40.06\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			MobileNet & \ \ \ \ \ \ \ \ \ \ \ - & 319 & 567436 & 0.8G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 16.61\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			MobileNet & \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 319 & 567436 & 0.8G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 36.59\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			GhostNet & \ \ \ \ \ \ \ \ \ \ \ - & 430 & 19200 & 0.2G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 16.22\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			GhostNet & \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 430 & 19200 & 0.2G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 27.68\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			CA\ \ \ \  & \ \ \ \ \ \ \ \ \ \ \ - & 304 & 18368 & 2.1G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 18.27\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			CA\ \ \ \  & \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 304 & 18368 & 2.1G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 28.45\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\

			\hline
		\end{tabular}
	\end{center}
\end{table}
\subsection{监测系统对比实验}
\begin{table} [htpb]
	\begin{center}
		%\setlength{\belowcaptionskip}{3mm}
		\caption{\ \ 实时监测系统效果对比示意}
		\label{table4-2}
		\footnotesize
		%\setlength{\tabcolsep}{1.8pt}
		\begin{tabular}{llrrrr}
			\hline
			\multirow{1}*{应用平台} & \multirow{1}*{是否应用 GPU } & \multirow{1}*{网络层数} & \multirow{1}*{参数量} & \multirow{1}*{浮点运算数（FLOPs）} & \multirow{1}*{实时监测帧率（FPS）}\\
			\hline \hline
			% $\checkmark$
			PC &  \ \ \ \ \ \ \ \ \ \ \ - & 192 & 7930 & 0.3G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 35.51\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			PC &  \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 192 & 7930 & 0.3G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 65.06\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			Xavier &  \ \ \ \ \ \ \ \ \ \ \ - & 192 & 7930 & 0.8G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 2.4\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			Xavier &  \ \ \ \ \ \ \ \ \ \ \ $\checkmark$ & 192 & 7930 & 0.3G\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  & 20.78\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
			\hline
		\end{tabular}
	\end{center}
\end{table}
\subsection{实际应用场景下结果展示}
\subsubsection{实时检测追踪系统}
\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.48\linewidth]{chap4/v4.png}
	\caption{\ \ 实时检测追踪系统}
	\label{fig4-12}
\end{figure}
\subsubsection{实时人流量监控系统}
\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.48\linewidth]{chap4/v2.jpg}
	\caption{\ \ 实时人流量监控系统}
	\label{fig4-13}
\end{figure}
\section{本章小结}

\chapter{总结与展望}
\section{全文总结}
\section{工作展望}

~\cite{1},\cite{2}，\cite{3},\cite{4}，\cite{5},\cite{6}，\cite{7},\cite{8}，\cite{9},\cite{10},
~\cite{11}，\cite{12}，\cite{13},\cite{14}，\cite{15},\cite{16}，\cite{17},\cite{18}，\cite{19},\cite{20},
~\cite{21}，\cite{22}，\cite{23},\cite{24}，\cite{25},\cite{26}，\cite{27},\cite{28}，\cite{29},\cite{30},
~\cite{31}，\cite{32}，\cite{33},\cite{34}，\cite{35},\cite{36}，\cite{37},\cite{38}，\cite{39},\cite{40},
~\cite{41}，\cite{42}，\cite{43},\cite{44}，\cite{45},\cite{46}，\cite{47},\cite{48}，\cite{49},\cite{50},
~\cite{51}，\cite{52}，\cite{53},\cite{54}，\cite{55},\cite{56}，\cite{57},\cite{58}，\cite{59},\cite{60},
~\cite{61}，\cite{62}，\cite{63},\cite{64}，\cite{65},\cite{66}，\cite{67},\cite{68}，\cite{69},\cite{70},
~\cite{71}，\cite{72}，\cite{73},\cite{74}，\cite{75},\cite{76}，\cite{77},\cite{78}，\cite{79},\cite{80},
~\cite{81}，\cite{82}，\cite{83},\cite{84}，\cite{85},\cite{86}，\cite{87},\cite{88}，\cite{89},\cite{90},
~\cite{91}，\cite{92}，